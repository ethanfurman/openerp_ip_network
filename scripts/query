#!/usr/local/bin/suid-python --virtualenv
"""\
Get and run the commands in IP Network Command section, collect and
process the data using the scripts from the configuration section, and
feed the results back to OpenERP.

Due to threading issues when running inside OpenERP, this utility exists to
do the heavy lifting outside the OpenERP process space.

Default time zone is America/Los Angeles.
"""

# imports

from __future__ import print_function
from aenum import MultiValueEnum
from antipathy import Path
from dbf import Date, DateTime, Time
from ipaddress import IPv4Network, IPv4Address
from scription import *
from openerplib import get_connection, get_records, AttrDict
from openerplib import DEFAULT_SERVER_DATE_FORMAT, DEFAULT_SERVER_DATETIME_FORMAT
from openerplib.dates import datetime_to_str, utc_datetime
from pprint import pformat
from Queue import Queue, Empty
from threading import Thread, Lock#, active_count#, current_thread
from traceback import format_exc
# from traceback import extract_tb, format_exc, format_list
import sys
import termios
import time
import re

import logging
import logging.handlers

import os
from pytz import timezone

utc = timezone('UTC')
if os.path.exists("/etc/timezone"):
    tz_value = False
    try:
        f = open("/etc/timezone")
        tz_value = f.read(128).strip()
    except Exception:
        tz_value = 'America/Los_Angeles'
    finally:
        f.close()
server_timezone = timezone(tz_value)

START = time.time()

# globals

VIRTUAL_ENV = os.environ['VIRTUAL_ENV']
CONFIG = Path('/%s/config/fnx.ini' % VIRTUAL_ENV)
MACHINES = Path('/%s/config/machines.dbf' % VIRTUAL_ENV)
UPDATE_OPENERP = Unknown
GUI = 0

try:
    settings = OrmFile(CONFIG)
except Exception:
    print('WARNING: unable to process configfile; all parameters must be specified', file=stderr)
    HOST = ''
    USER = ''
    DB = ''
    PW = ''
    NETWORK_PW = ''
else:
    HOST = settings.openerp.host
    USER = settings.openerp.user
    DB = settings.openerp.db
    PW = settings.openerp.pw
    NETWORK_PW = settings.network.pw

# API

@Script(
        host=('host where OpenERP instance is running', OPTION, None),
        db=('database to use', OPTION, None),
        user=('login name to use', OPTION, None),
        pw=('password for login name', OPTION, None),
        log=Spec('logging level to use', OPTION, abbrev=None, force_default='INFO', type=u.upper),
        log_file=Spec('file to log to', OPTION, abbrev=None, force_default='%s/var/log/openerp/ip_network_query.log' % VIRTUAL_ENV),
        )
def main(log, log_file, host=HOST, db=DB, user=USER, pw=''):
    global Type, convert, _logger, oe, device_type, Status, TypeSource
    # set up logging
    log_level = getattr(logging, log)
    main_logger = logging.getLogger()
    handler = logging.handlers.RotatingFileHandler(log_file, backupCount=61)
    handler.doRollover()
    handler.setFormatter(Formatter('%(asctime)s %(pid)d %(name)s %(levelname)s: %(message)s'))
    main_logger.addHandler(handler)
    _logger = logging.getLogger('ip_network_query')
    _logger.setLevel(log_level)
    _logger.debug('logging is on-line')
    # set up openerp connection info
    if host:
        module.HOST = host
    if db:
        module.DB = db
    if user:
        module.USER = user
    if pw:
        module.PW = pw
    for req in ('HOST', 'USER', 'DB', 'PW'):
        if not module[req]:
            raise SystemExit('%r required; use --help for more info' % req)
    _logger.debug('host: %r', module.HOST)
    _logger.debug('user: %r', module.USER)
    _logger.debug('db  : %r', module.DB)
    # link to openerp tables
    oe = get_connection(hostname=HOST, database=DB, login=USER, password=PW)
    oe.network = oe.get_model('ip_network.network')
    oe.device = oe.get_model('ip_network.device')
    Status = oe.device.DeviceStatus
    TypeSource = oe.device.DeviceTypeSource
    oe.command = oe.get_model('ip_network.extra.command')
    oe.type = oe.get_model('ip_network.device.type')
    Type = IDEnum(
            'Type',
            [
                (t.short_name, (t.id, 'type.'+t.short_name))
                for t in get_records(oe.type)
                ])
    convert = {
            Status: lambda v: v.db,
            Type: lambda v: v.value,
            Date: lambda v: v.strftime(DEFAULT_SERVER_DATE_FORMAT),
            Time: lambda v: v.tofloat(),
            DateTime: lambda v: local2utc(v),
            IPv4Address: lambda v: str(v),
            }

    # create device test function
    tests = ['def device_type(ports):']
    for dt in sorted(get_records(oe.type), key=lambda dt: dt.sequence):
        if dt.test:
            tests.append('    if %s: return %s' % (dt.test, Type(dt.id)))
    tests.append('    else: return Type.unknown')
    device_type = '\n'.join(tests)
    _logger.debug('device_type function:\n%s', device_type)
    sandbox = {'Type': Type}
    exec(device_type, sandbox)
    device_type = sandbox['device_type']


@Command(
        networks=Spec('ip/networks to run commands for', MULTIREQ, ),
        scan_timeout=Spec('how long to allow ip scan to run', OPTION),
        threads=Spec('number of threads to use', OPTION, 'j'),
        delay=Spec('delay between port scans', OPTION),
        update=Spec('update OpenERP with results', FLAG,),
        gui=Spec('positive value actives GUI and is line_length', OPTION),
        )
def for_openerp(networks=None, scan_timeout=900, threads=32, delay=1, update=True, gui=0):
    "run all commands and update OpenERP with the results"
    global SCAN_TIMEOUT, UPDATE_OPENERP, GUI, OE_DEVICES
    UPDATE_OPENERP = update
    SCAN_TIMEOUT = scan_timeout
    GUI = gui
    _logger.info('in for_openerp')
    _logger.debug('networks: %r', networks)
    _logger.debug('scan_timeout: %r', scan_timeout)
    if not networks:
        # get them from OpenERP
        _logger.debug('getting networks from OpenERP')
        networks = [
                unicode(n.network)
                for n in get_records(oe.network)
                ]
    _logger.debug('networks: %r', networks)
    commands = [
            c
            for c in get_records(oe.command)
            if c.where in ('ssh', 'local')
            ]
    _logger.debug('valid commands: %r', commands)
    addresses = []
    for network in networks:
        if network.endswith('/32'):
            addresses.extend(list(IPv4Network(network)))
        else:
            addresses.extend([h for h in IPv4Network(network).hosts()])
    if not addresses:
        abort('no addresses found in %s' % networks)
    _logger.debug('addresses to check: %s', ', '.join(str(d) for d in addresses))
    # sort addresses that actually exist first
    OE_DEVICES = dict(
        (IPv4Address(unicode(d.ip_addr)), d)
        # (IPv4Address(unicode(d.ip_addr)), {'id': d.id, 'ip_addr': d.ip_addr, 'type_id': Type(d.type_id), 'type_source': d.type_source})
        for d in get_records(oe.device, fields=['id', 'ip_addr', 'status', 'type_id', 'type_source', 'last_comms'])
        )
    # for dev in OE_DEVICES.values():
    #     dev.type_id = Type(dev.type_id.id)
    # addresses.sort(key=lambda a: (1, 0)[a in OE_DEVICES])
    errors = {}
    try:
        if threads:
            process_simultaneous_hosts_commands(commands, addresses, errors, pool_size=threads, delay=delay)
        else:
            process_sequential_hosts_commands(commands, addresses, errors)
    finally:
        display_errors(errors)
        Execute('/usr/bin/curl http://192.168.11.16:3500/192.168.11.16/daily/ip_network_query')


@Command(
        )
def list_commands():
    "list the available commands"
    echo('Available commands:')
    for cmd in get_records(oe.command):
        if cmd.where not in ('ssh', 'local'):
            continue
        echo('  %2d: %s -- %s' % (cmd.sequence, cmd.name, cmd.command), end='')
        echo()


@Command(
        command=Spec('which command to run', ),
        networks=('which network(s) to test against', MULTIREQ),
        scan_timeout=Spec('how long to allow ip scan to run', OPTION),
        threads=Spec('number of threads to use', OPTION, 'j'),
        update=Spec('update OpenERP with results', FLAG),
        gui=Spec('positive value actives GUI and is line_length', OPTION),
        )
def test(command, networks, scan_timeout=60, threads=0, update=False, gui=0):
    "run any 1-10 commands, plus the specified COMMAND, against IP"
    global SCAN_TIMEOUT, UPDATE_OPENERP, GUI, OE_DEVICES
    SCAN_TIMEOUT = scan_timeout
    UPDATE_OPENERP = update
    GUI = gui
    OE_DEVICES = dict(
        (IPv4Address(unicode(d.ip_addr)), d.updated(type_id=Type(d.type_id)))
        for d in get_records(oe.device, fields=['id', 'ip_addr', 'type_id', 'type_source'])
        )
    command = command.lower().replace(' ', '_').replace('-', '_')
    commands = get_records(oe.command)
    valid_commands = [c for c in commands if c.where in ('ssh', 'local')]
    valid_command_names = [c.name.lower().replace(' ', '_') for c in valid_commands]
    print('valid command names: %r' % (valid_command_names, ), verbose=3)
    if command == 'all':
        cmds = valid_commands
    elif command not in valid_command_names:
        abort('unrecognized command: %s  [choices: %s]' % (command, ', '.join(valid_command_names)))
    else:
        cmds = [c for c in commands if c.sequence <= 10 or c.name.lower().replace(' ', '_') == command]
    addresses = []
    for network in networks:
        hosts = [h for h in IPv4Network(network).hosts()]
        if not hosts:
            hosts = list(IPv4Network(network))
        addresses.extend(hosts)
    print('addresses: %r' % addresses, verbose=3)
    if not addresses:
        abort('no network specified')
    errors = {}
    if not threads:
        results = process_sequential_hosts_commands(cmds, addresses, errors)
    else:
        results = process_simultaneous_hosts_commands(cmds, addresses, errors, threads, delay=0.1)
    echo()
    for ip, result in sorted(results.items()):
        echo(ip)
        for cmd_name, subdict in sorted(result.items()):
            if subdict is not None and cmd_name != '_errors':
                echo('    ', cmd_name, end='')
                for k, v in sorted(subdict.items()):
                    if k == 'value':
                        continue
                    echo(' [%s: %r]' % (k, v), end='')
                echo(end=': ')
                data = subdict.get('value', {})
                if isinstance(data, basestring):
                    data = data.strip().split('\n')
                    if len(data) == 1:
                        echo(data[0])
                    else:
                        echo()
                        for line in data:
                            echo('        ', line)
                else:
                    echo(repr(data))
    display_errors(errors)


# support

max_elapsed = 0

def local2utc(dt):
    dt = server_timezone.localize(dt._datetime)
    dt = server_timezone.normalize(dt)
    dt = dt.strftime(DEFAULT_SERVER_DATETIME_FORMAT)
    return dt


class Grid(object):
    """
    simple grid to show progress
    """

    def __init__(self, addresses, width=80):
        # addresses is a list
        self.total = len(addresses)
        # width -= 20
        self.line_length = width // 16
        self.line_length *= 16
        self.height = self.total // self.line_length + 1
        self.status_line = self.height + 3
        self.last_line = self.height + 5
        self.clear_grid()
        self.draw_grid(addresses)

    def clear_grid(self):
        if GUI:
            echo('\x1b[0;0H', end='')
            echo(' ' * 30000)

    def draw_grid(self, addresses):
        if GUI:
            echo('\x1b[0;0H', end='')
            i = 0
            while i <= len(addresses):
                echo('%15s' % (addresses[i].exploded, ))
                i += self.line_length

    def update_grid(self, pos, state):
        if GUI:
            row, col = divmod(pos, self.line_length)
            row += 1
            col = col + 20
            echo('\x1b[%s;%sH%s' % (row, col, state), end='')
            echo('\x1b[%s;0H' % self.last_line, end='')

    def display_after_grid(self, text, status=False):
        if GUI:
            if status:
                echo('\x1b[%s;0H%s                                        ' % (self.status_line, text), sep='')
            else:
                echo('\x1b[%s;0H%s' % (self.last_line, text), sep='')
                self.last_line += 1

def update_openerp(ip, results):
    "find and update the appropriate record in OpenERP"
    print('[%15.5f]  looking for %s on OpenERP' % (time.time()-START, ip))
    if not results:
        print('no results for', ip, verbose=2)
        return False
    ip = str(ip)
    values = {}
    print('results in update_openerp', results)
    for field, subdict in results.items():
        try:
            value = subdict['value']
        except KeyError:
            # status only result
            field = 'status'
            value = subdict['status']
        value = convert.get(type(value), lambda v: v)(value)
        if field == '_errors':
            field = 'errors'
        values[field] = value
    print('converted:', values)
    if ip != values['ip_addr']:
        raise ValueError('IP %r is not the same as ip_addr %r' % (ip, values['ip_addr']))
    device = get_records(oe.device, domain=[('ip_addr','=',ip)], fields=['id', 'ip_addr', 'name', 'type_source'], max_qty=1)
    if device:
        # update record
        print('[%15.5f]  updating device %s' % (time.time()-START, ip), verbose=2)
        print('                   using: %r' % (values, ), verbose=3)
        [device] = device
        # don't update device type if status is offline or is being user managaed, unless device type is unknown
        if values.get('type_id') is Type.unknown:
            pass
        elif values['status'] is Status.offline or device.type_source is oe.device.DeviceTypeSource.user:
            values.pop('type_id', None)
        try:
            oe.device.write(device.id, values)
            print('                   done', verbose=3)
        except Exception as exc:
            print('                   failed', verbose=3)
            raise UpdateFailure('Unable to update %r [id: %r] [%s]' % (ip, device.id, exc))
    else:
        if values['status'] not in (Status.offline, ):
            # create record
            if 'type_id' not in values:
                # must be unknown
                values['type_id'] = Type.unknown
            values['type_source'] = oe.device.DeviceTypeSource.system
            print('[%15.5f]  creating device for %s' % (time.time()-START, ip), verbose=2)
            print('                   using: %r' % (values, ), verbose=3)
            try:
                oe.device.create(values)
                print('                   done', verbose=3)
            except Exception as exc:
                print('                   failed', verbose=3)
                raise CreateFailure('Unable to create %r [%s]' % (ip, exc))
        else:
            return False
    return True

def process_sequential_hosts_commands(commands, addresses, errors):
    print('[%15.5f]  sesquentialy queued to run:  %s' % (time.time()- START, ', '.join([c.name for c in commands])), verbose=1)
    print('                   for', addresses, verbose=2)
    print()
    global grid
    grid = Grid(addresses, GUI or 80)
    results = dict([(a, {}) for a in addresses])
    for host in addresses:
        host_results, host_errors = process_host(host, commands)
        results[host] = host_results
        for ip, outputs in host_errors.get('by_ip', {}).items():
            for output, command_names in outputs.items():
                errors.setdefault('by_ip', {}).setdefault(ip, {}).setdefault(output, []).extend(command_names)
        for cmd, problem in host_errors.get('by_command', {}).items():
            errors.setdefault('by_command', {}).setdefault(cmd, []).append(problem)
        print([(str(k), str(v)) for k, v in results.items()], border='table', verbose=3)
    return results

def process_simultaneous_hosts_commands(commands, addresses, errors, pool_size, delay=0):
    print('[%15.5f]  simultaneously queued to run:  %s' % (time.time()-START, ', '.join([c.name for c in commands])), verbose=1)
    print('                  for', addresses, verbose=2)
    print()
    global grid
    grid = Grid(addresses, GUI or 80)
    results = dict([(a, {}) for a in addresses])
    # set up queues for parallel execution
    with TaskPool(pool_size, delay=delay, name='nmap') as pool:
        submitted = 0
        for seq, ip in enumerate(addresses):
            pool.add_task(process_host, seq, address=ip, commands=commands)
            submitted += 1
        print('[%15.5f]  %d tasks submitted' % (time.time()-START, submitted), verbose=2)
        while pool.active:
            task = pool.get_result()
            ip = task.kwds['address']
            host_results, host_errors = task()
            status = host_results['status']['value']
            results[ip] = host_results
            ch = None
            if status is Status.offline:
                if ip in OE_DEVICES:
                    ch = 'O'
                else:
                    ch = '-'
            elif status is Status.unknown:
                ch = 'T'
            for ip, outputs in host_errors.get('by_ip', {}).items():
                for output, command_names in outputs.items():
                    errors.setdefault('by_ip', {}).setdefault(ip, {}).setdefault(output, []).extend(command_names)
                    ch = 'E'
            for cmd, problem in host_errors.get('by_command', {}).items():
                errors.setdefault('by_command', {}).setdefault(cmd, []).append(problem)
            pool.result_done(task, ch=ch)
    return results

def process_host(address, commands):
    _logger.info('%r', address)
    results = {}
    status = []
    clues = set()
    errors = {}
    exceptions = []
    for cmd in commands:
        print('[%15.5f]  %s  ->  %r' % (time.time()-START, address, cmd.command), verbose=2)
        try:
            ran = single_command(cmd, results, errors, address)
        except ConnectionError as exc:
            clues.add(exc.__doc__)
            status.append(Status.danger)
            exceptions.append(str(exc))
            break
        except UnableToContact as exc:
            exceptions.append(str(exc))
            results[cmd.name] = {'status': Status.offline}
            ran = True
        except TarPit as exc:
            exceptions.append(str(exc))
            print('setting results[%r] to %r' % (cmd.name, Status.unknown), verbose=3)
            results[cmd.name] = {'status': Status.unknown}
            ran = True
        except (JobFailed, ScriptError) as exc:
            print('(JobFailed, ScriptError) results -> %r' % (results, ), verbose=3)
            exceptions.append(str(exc))
            results[cmd.name] = {'status': Status.danger}
            ran = True
        if not ran:
            continue
        print('processing results for:', ', '.join(results), verbose=3)
        for command, subdict in results.items():
            if 'status' in subdict:
                cmd_status = subdict['status']
                print('  appending status %r for command %r' % (cmd_status, command), verbose=3)
                if not isinstance(cmd_status, Status):
                    cmd_status = Status(cmd_status)
                status.append(cmd_status)
                if cmd_status in (Status.warning, Status.danger):
                    clues.add(command)
        if Status.offline in status or Status.unknown in status:
            break
    if status:
        # combine various statusi into one status field
        results['status'] = {'value': max(status)}
        results['clues'] = {'value': ', '.join(clues)}
    results['_errors'] = {'value': '\n=============\n'.join(exceptions)}
    print('results keys: %r' % results.keys(), verbose=3)
    # write the results to OpenERP... maybe
    for key, result in sorted(results.items()):
        _logger.debug('%r; %s: %r', address, key, result)
    if UPDATE_OPENERP:
        try:
            if not update_openerp(address, results):
                # records not written (offline and non-existent), do not need to be
                # displayed as errors
                errors.clear()
        except Exception:
            output = format_exc().strip()
            errors.setdefault('by_ip', {}).setdefault(address, {}).setdefault(output, []).append('update_openerp')
    print('          finished processing host', verbose=3)
    return results, errors


def single_command(command, results, errors, address):
    global max_elapsed
    _logger.debug('%r; command: %r', address, command.name)
    print('[%15.5f]  processing %r' % (time.time()-START, command.name))
    commandline = command.command % {'ip':address}
    if command.where == 'ssh':
        password = NETWORK_PW
        pty = True
        commandline = (
            'ssh root@%(ip)s -o StrictHostKeyChecking=no -o HashKnownHosts=no -o ConnectTimeout=30 '
            + commandline
            ) % {'ip':address}
    else:
        password = None
        pty = False
    _logger.debug('%r; command line: %r', address, commandline)
    print('[%15.5f]  final command: %r' % (time.time()-START, commandline))
    print('                   Types:', list(Type), verbose=4)
    device = OE_DEVICES.get(
            address,
            AttrDict(id=False, ip_addr=address, name=False, type_source=TypeSource.system, type_id=Type.unknown, last_comms=False),
            )
    print('                   device: %r' % device, verbose=2)
    if device.type_source is TypeSource.user:
        results['type_id'] = {'value': device.type_id}
    run_for = [Type(id) for id in command.run_for_ids]
    print('                   restrict to:', ', '.join([str(t) for t in run_for]) or '-', verbose=3)
    if run_for and results.get('type_id', {}).get('value', None) not in run_for:
        _logger.debug('%r; skpping', address)
        print('                   skipping command', command.name)
        return False
    start_time = time.time()
    job = Job(commandline, pty=pty)
    failed = None
    try:
        job.communicate(timeout=60, password=password)
    except FailedPassword as failed:
        pass
    except Exception as failed:
        pass
    finally:
        job.close()
    if failed is not None:
        print('failed: %s' % failed, verbose=3)
    _logger.debug('%r; return code: %r\n%s', address, job.returncode, job.stdout + '\n-------\n' + job.stderr)
    end_time = time.time()
    elapsed_time = end_time - start_time
    print('                   %s took %s to run' % (command.name, seconds2time(elapsed_time)), verbose=2)
    if not job.returncode and elapsed_time > max_elapsed:
        max_elapsed = elapsed_time
        grid.display_after_grid('%s took %s to run' % (command.name, seconds2time(elapsed_time)), status=True)
    print('job stdout: %r' % job.stdout.strip(), verbose=3)
    lines = job.stdout.strip().split('\n')
    if '[sudo]' in lines[0] or password and password in lines[0]:
        lines.pop(0)
    text = '\n'.join(lines)
    if job.returncode:
        print('                   job failed', verbose=3)
        message = []
        if text.strip():
            message.append('[stdout]')
            message.append('   %s' % '\n   '.join(lines))
        message.append('[stderr:  %s]' % job.returncode)
        message.append('   %s' % '\n   '.join([l for l in job.stderr.strip().split('\n') if 'WARNING: Running Nmap ' not in l]))
        job_error = '\n'.join(message)
        print('                   job output:', verbose=3)
        print('%s' % (job_error, ), verbose=3)
        errors.setdefault('by_ip', {}).setdefault(address, {}).setdefault(job_error, []).append(command.name)
        errors.setdefault('by_command', {})[command.name] = address
        results['status'] = {'value': Status.danger}
        stderr = job.stderr.lower()
        if isinstance(failed, FailedPassword):
            raise InvalidPassword(str(job.stderr))
        elif (     'connection closed by' in stderr
                or 'connection reset by' in stderr
                or 'connection timed out during banner exchange' in stderr
                or 'no matching key exchange method' in stderr
            ):
            raise ConnectionError(job.stderr)
        elif 'remote host identification has changed' in job.stderr.lower():
            raise HostIDChanged(job.stderr)
        elif command.name == 'Network Search':
            # results['portscan'] = {'status': {'value': Status.unknown}}
            results['status'] = {'value': Status.unknown}
            results['ip_addr'] = {'value': address}
            results['type_id'] = {'value': Type.tarpit}
            raise TarPit('no Network Search results\n\n%s\n\n===================' % '\n'.join(message))
        else:
            raise JobFailed('error running %s:\n%s' % (command.name, job_error))
    else:
        print('                   job output:\n%s' % (text, ), verbose=3)
    sandbox = {
            'text':text,
            'result':results,
            'ref':Type,
            'Type':Type,
            'device_type':device_type,
            'ip_addr':str(address),
            'Execute':Execute,
            'cmd_name': command.name,
            'Blocks':Blocks,
            'Status':oe.device.DeviceStatus,
            'clock':lambda: datetime_to_str(utc_datetime()),
            're':re,
            }
    _logger.debug('before results:\n%s' % pformat(results))
    try:
        exec(command.script, sandbox)
        _logger.debug('after results:\n%s' % pformat(results))
        for field_name, subdict in sandbox['result'].items():
            print('-----', verbose=3)
            print('field_name: %r' % (field_name, ), verbose=3)
            print('subdict: %r' % (subdict, ), verbose=3)
            # print('%s: %r' % (field_name, subdict['value']), verbose=3)
        print('-----', verbose=3)
    except Exception:
        job_error = '%(stdout)s\n---\n%(stderr)s' % {
                'stdout': job.stdout.strip(),
                'stderr': format_exc().strip(),
                }
        errors.setdefault('by_ip', {}).setdefault(address, {}).setdefault(job_error, []).append(command.name)
        errors.setdefault('by_command', {})[command.name] = address
        raise ScriptError('error processing %s results:\n%s' % (command.name, job_error))
    print('command.name', command.name, verbose=3)
    print('results', results, verbose=3)
    if command.name == 'Network Search': 
        if 'ip_addr' not in results:
            # make sure ip_addr is set
            results['ip_addr'] = {'value': address}
        # if results['portscan']['status'] is not Status.offline:
        if results['portscan']['status'] is not Status.offline:
            results['last_comms'] = {'value': DateTime.now()}
        else:
            # Open Ports should be the first thing that runs
            # if there are no results after this, no point in continuing
            # with this host
            #
            # if device is in system as TarPit, but no connection was ever made (last_comms is False)
            # change device type from Tarpit to Unknown
            if device and device.type_id is Type.tarpit and not device.last_comms:
                results['type_id'] = {'value': Type.unknown}
            #
            # only record errors for this host if it already had an entry in OpenERP
            print('                   device:', device, verbose=3, border='lined')
            # results['status'] = {'value': Status.offline}
            if device.id and device.status is not Status.retired:
                errors.setdefault('by_ip', {})
                errors.setdefault('by_command', {})['Unreachable Hosts'] = address
            raise UnableToContact('network_search failed')
    # sandbox['result'] should be, e.g. with hostname:
    #   {
    #     'hostname': {'value':'falcon-11-100'},
    #     'hostname': {'value':'openerp'},
    #   }
    # this allows a script to set more than one field at a time
    return True


class Blocks(object):
    "yields one block of text at a time"
    def __init__(self, text, length=None):
        self.lines = text.strip().split('\n')
        self.lines.reverse()
        self.length = length
    def __iter__(self):
        lines = self.lines
        length = self.length
        while 'processing lines':
            block = []
            while lines:
                line = lines.pop()
                if length is None and not line.strip():
                    # if blocks are blank-line delimited
                    break
                block.append(line)
                if len(block) == length:
                    # if blocks are fixed-size
                    break
            if block:
                yield block
            if not lines:
                break


class DelayQueue(object):
    "Queue that releases items at least n seconds apart"

    __get_lock = Lock()

    def __init__(self, maxsize=0, delay=0, name='unknown'):
        self.__dict__['queue'] = Queue(maxsize)
        self.__dict__['delay'] = delay
        self.__dict__['_last_access'] = 0
        self.__dict__['_name'] = name

    # Automatic delegation
    def __getattr__(self, attr):
        return getattr(self.queue, attr)

    def __setattr__(self, attr, value):
        if attr in self.__dict__:
            self.__dict__[attr] = value
        else:
            setattr(self.queue, attr, value)

    # overrides
    def get(self):
        with self.__get_lock:
            now = time.time()
            result = self.queue.get()
            passed = now - self._last_access
            delay = self.delay - passed
            if result is not None and passed < self.delay:
                time.sleep(delay)
            now = time.time()
            self._last_access = now
            return result



class TaskPool(object):
    "Pool of threads consuming tasks from a queue"

    def __init__(self, num_threads, delay=0, name='strange'):
        self.size = num_threads
        self.tasks = DelayQueue(delay=delay, name=name)
        self.results = Queue()
        self._active = 0
        self.abort = False
        self.is_running = False
        self._name = name

    @property
    def active(self):
        return self._active

    @active.setter
    def active(self, value):
        self._active = value

    def __enter__(self):
        self.start()
        return self

    def __exit__(self, cls, exc, tb):
        if (cls, exc, tb) != (None, None, None):
            # escaped exception, abort any queued tasks
            self.abort = True
        else:
            self.shutdown()
        time.sleep(5)

    def add_result(self, result):
        self.results.put(result)

    def add_task(self, func, seq, *args, **kwds):
        "Add a task to the queue, incrementing work counter"
        self.active += 1
        if isinstance(func, (Task, type(None))):
            task = func
        else:
            task = Task(func, *args, **kwds)
        task.num = seq
        grid.update_grid(seq, '.')
        self.tasks.put(task)

    def get_result(self):
        "Get result from queue, decrementing work counter"
        if not self.active:
            raise Empty
        res = self.results.get()
        grid.update_grid(res.num, 'p')
        time.sleep(0.1)
        self.active -= 1
        if not isinstance(res, Task):
            # problem occured in TaskPool framework...
            cls, exc, tb = res
            raise_with_traceback(exc, tb)
        return res

    def get_task(self):
        return self.tasks.get()

    def result_done(self, task, ch=None):
        if ch is None:
            ch = '+'
        grid.update_grid(task.num, ch)
        self.results.task_done()

    def shutdown(self):
        "Signal threads to exit, wait until they have"
        for _ in range(self.size):
            self.tasks.put(None)
        self.wait_completion()
        self.is_running = False

    def start(self):
        "Start threads running"
        if not self.is_running:
            for _ in range(self.size):
                TaskThread(self)
            self.is_running = True

    def task_done(self):
        self.tasks.task_done()

    def wait_completion(self):
        "Wait for completion of all the tasks in the queue"
        self.tasks.join()


class TaskThread(Thread):
    "Thread executing tasks from a given tasks queue"

    count = 0

    def __init__(self, pool):
        Thread.__init__(self)
        self.pool = pool
        self.daemon = True
        self.id = self.count
        self.__class__.count += 1
        self.start()

    def run(self):
        try:
            while True:
                if self.pool.abort:
                    break
                task = self.pool.get_task()
                # also check after getting task as a delay may have occured
                if self.pool.abort:
                    break
                try:
                    if task is None:
                        break
                    task.activate()
                    self.pool.add_result(task)
                except Exception:
                    # shouldn't happen, but just in case...
                    self.pool.add_result(sys.exc_info())
                finally:
                    self.pool.task_done()
        except Exception as exc:
            exc
            pass


class Task(object):
    "Light-weight task proxy used by TaskPool"

    def __init__(self, func, *args, **kwds):
        self.pending = True
        self.func = func
        self.args = args
        self.kwds = kwds
        self.result = None
        self.error = None

    def __call__(self):
        "Return result, running if necessary"
        if self.pending:
            self.activate()
        if self.error is not None:
            cls, exc, tb = self.error
            raise_with_traceback(exc, tb)
        else:
            return self.result

    def __repr__(self):
        return 'Task(%r)' % (
                    self.func,
                    # ', '.join(self.args),
                    # ', '.join(['%s=%s' % (k, v) for k, v in self.kwds.items()]),
                    )

    def activate(self):
        "Run task and save result"
        grid.update_grid(self.num, 'R')
        time.sleep(0.1)
        try:
            self.result = self.func(*self.args, **self.kwds)
            grid.update_grid(self.num, 'd')
            time.sleep(0.1)
        except:
            self.error = sys.exc_info()
            grid.update_grid(self.num, 'x')
            time.sleep(0.1)
        self.pending = False



class UnableToContact(Exception):
    "failed ping test"


class TarPit(Exception):
    "too slow to respond"


class CreateFailure(Exception):
    "unable to create record in OpenERP"


class UpdateFailure(Exception):
    "unable to write record in OpenERP"


class ScriptError(Exception):
    "script raised an exception"


class JobFailed(Exception):
    "external job had non-zero return code"


class ConnectionError(JobFailed):
    "unable to establish connection"


class InvalidPassword(ConnectionError):
    "password failed"


class HostIDChanged(ConnectionError):
    "remote host identification changed"


class IDEnum(MultiValueEnum):
    "primary value should be the id of the matching record"


class Formatter(logging.Formatter):
    def format(self, record):
        record.pid = os.getpid()
        return logging.Formatter.format(self, record)


def display_errors(errors):
    # errors = {
    #           'by_command': {
    #                          'command1': [ip1, ip2, ...],
    #                          'command2': [ip1, ip5, ...],
    #                          },
    #           'by_ip': {
    #                     ip1: {
    #                           output-a: ['command1', 'command3'],
    #                           output-b: ['command2'],
    #                           },
    #                     ip2: {
    #                           output-c: ['command1'],
    #                           },
    #                     ip5: {
    #                           output-d: ['command2'],
    #                           },
    #                     },
    #            }
    if errors:
        for command, ips in sorted(errors.get('by_command', {}).items()):
            error('='*15)
            if len(ips) == 1:
                error('%s: %s' % (command, ips[0]))
            else:
                error('%s:' % (command, ))
                error('   ' + '\n   '.join([str(ip) for ip in ips]))
        if errors.get('by_command') and errors.get('by_ip'):
            error('='*15)
        for ip, outputs in sorted(errors.get('by_ip', {}).items()):
            error('='*15, ip, '-'*15, sep='\n')
            text = []
            for output, commands in outputs.items():
                output = output.replace('\n', '\n   |    ')
                names = '\n   | '.join([c for c in sorted(commands)])
                text.append('   | %s\n   |    %s' % (names, output))
            error('\n   |--------------------------------------------------------\n'.join(text))

time_units = {'d':86400, 'h':3600, 'm':60, 's':1}

def time2seconds(time):
    "convert time to seconds (e.g. 2m -> 120)"
    # if all digits, must be seconds already
    if not time:
        return 0
    elif isinstance(time, (int, long)):
        return time
    text = time
    if text[0] == '-':
        sign = -1
        text = text[1:]
    else:
        sign = +1
    if text.isdigit():
        return sign * int(text)
    wait_time = 0
    digits = []
    for c in text:
        if c.isdigit():
            digits.append(c)
            continue
        number = int(''.join(digits))
        c = c.lower()
        if c not in ('dhms'):
            abort('invalid wait time: %r' % time)
        wait_time += time_units[c] * number
        digits = []
    else:
        if digits:
            # didn't specify a unit, abort
            abort('missing trailing time unit of h, m, or s in %r' % time)
    return wait_time
TimeLapse = time2seconds

def seconds2time(seconds):
    if seconds < 0:
        raise ValueError('seconds cannot be negative')
    result = ''
    for unit in 'dhms':
        size = time_units[unit]
        if seconds < size:
            continue
        amount, seconds = divmod(seconds, size)
        result = ('%s %i%s' % (result, amount, unit)).strip()
        if seconds == 0:
            break
    return result or '0s'

stdout_settings = None
if os.isatty(sys.stdout.fileno()):
    stdout_settings = termios.tcgetattr(sys.stdout.fileno())
try:
    Run()
finally:
    if stdout_settings != None and os.isatty(sys.stdout.fileno()):
        termios.tcsetattr(sys.stdout, termios.TCSADRAIN, stdout_settings)
